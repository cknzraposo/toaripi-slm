# Environment Configuration for Toaripi SLM
# Copy this file to .env and fill in your values

# Python Environment
PYTHON_VERSION=3.11

# Training Configuration
WANDB_PROJECT=toaripi-slm
WANDB_API_KEY=your_wandb_api_key_here
HF_TOKEN=your_huggingface_token_here

# Model Settings
DEFAULT_MODEL_NAME=microsoft/DialoGPT-medium
OUTPUT_DIR=./models/hf
CHECKPOINT_DIR=./checkpoints

# Data Configuration
DATA_DIR=./data
RAW_DATA_DIR=./data/raw
PROCESSED_DATA_DIR=./data/processed
SAMPLES_DIR=./data/samples

# Training Parameters
BATCH_SIZE=4
LEARNING_RATE=2e-5
NUM_EPOCHS=3
MAX_LENGTH=512
GRADIENT_ACCUMULATION_STEPS=4

# Hardware Configuration
DEVICE=auto
CUDA_VISIBLE_DEVICES=0
USE_FP16=true
USE_GRADIENT_CHECKPOINTING=true

# Logging and Monitoring
LOG_LEVEL=INFO
SAVE_STEPS=500
EVAL_STEPS=500
LOGGING_STEPS=100

# Edge Deployment
QUANTIZATION_TYPE=dynamic
TARGET_PLATFORM=cpu
GGUF_OUTPUT_DIR=./models/gguf

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1
API_RELOAD=true

# Testing
TEST_MODEL_PATH=./models/hf/toaripi-test
TEST_DATA_PATH=./data/samples/parallel_data.csv